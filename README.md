# DevOps Lab - Production Kubernetes Platform

> Complete end-to-end DevOps pipeline featuring Kubernetes, GitOps, Infrastructure as Code, and CI/CD automation

<div align="center">

### Technologies Used

[![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white)](https://kubernetes.io/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://docker.com/)
[![Helm](https://img.shields.io/badge/Helm-0F1689?style=for-the-badge&logo=helm&logoColor=white)](https://helm.sh/)
[![ArgoCD](https://img.shields.io/badge/ArgoCD-EF7B4D?style=for-the-badge&logo=argo&logoColor=white)](https://argo-cd.readthedocs.io/)
[![Terraform](https://img.shields.io/badge/Terraform-7B42BC?style=for-the-badge&logo=terraform&logoColor=white)](https://terraform.io/)
[![AWS](https://img.shields.io/badge/AWS-FF9900?style=for-the-badge&logo=amazonaws&logoColor=white)](https://aws.amazon.com/)

[![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=for-the-badge&logo=github-actions&logoColor=white)](https://github.com/features/actions)
[![Jenkins](https://img.shields.io/badge/Jenkins-D24939?style=for-the-badge&logo=jenkins&logoColor=white)](https://jenkins.io/)
[![Prometheus](https://img.shields.io/badge/Prometheus-E6522C?style=for-the-badge&logo=prometheus&logoColor=white)](https://prometheus.io/)
[![Grafana](https://img.shields.io/badge/Grafana-F46800?style=for-the-badge&logo=grafana&logoColor=white)](https://grafana.com/)
[![Node.js](https://img.shields.io/badge/Node.js-339933?style=for-the-badge&logo=nodedotjs&logoColor=white)](https://nodejs.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=for-the-badge&logo=postgresql&logoColor=white)](https://postgresql.org/)

</div>

## üìã Project Overview

This project demonstrates a **production-ready DevOps pipeline** with modern cloud-native practices, showcasing:

- ‚úÖ **Containerized Application** - Node.js REST API with PostgreSQL
- ‚úÖ **Kubernetes Orchestration** - EKS cluster with Helm package management
- ‚úÖ **GitOps Deployment** - ArgoCD auto-sync and self-healing
- ‚úÖ **Infrastructure as Code** - Terraform provisioning AWS resources
- ‚úÖ **CI/CD Automation** - GitHub Actions + Jenkins pipelines
- ‚úÖ **Monitoring & Observability** - Prometheus + Grafana stack
- ‚úÖ **Auto-scaling** - HPA based on CPU/memory metrics
- ‚úÖ **Production Security** - RBAC, Secrets, non-root containers

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   GitHub Repository                         ‚îÇ
‚îÇ             (Single Source of Truth)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ                          ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  GitHub Actions       ‚îÇ  ‚îÇ   Jenkins Pipeline  ‚îÇ
    ‚îÇ  ‚Ä¢ Test & Build       ‚îÇ  ‚îÇ   ‚Ä¢ Local Dev       ‚îÇ
    ‚îÇ  ‚Ä¢ Push to ghcr.io    ‚îÇ  ‚îÇ   ‚Ä¢ Minikube        ‚îÇ
    ‚îÇ  ‚Ä¢ Helm Version Bump  ‚îÇ  ‚îÇ   ‚Ä¢ Health Checks   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ              ArgoCD (GitOps)                        ‚îÇ
    ‚îÇ     Auto-sync every 3min ‚Ä¢ Self-healing             ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ          Kubernetes Cluster (AWS EKS)               ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
    ‚îÇ  ‚îÇ  Node App       ‚îÇ  ‚îÇ Prometheus ‚îÇ  ‚îÇ Grafana  ‚îÇ ‚îÇ
    ‚îÇ  ‚îÇ  (3 replicas)   ‚îÇ  ‚îÇ (metrics)  ‚îÇ  ‚îÇ (dashb.) ‚îÇ ‚îÇ
    ‚îÇ  ‚îÇ  HPA: 2-10 pods ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
    ‚îÇ  ‚îÇ   PostgreSQL RDS (Multi-AZ)                  ‚îÇ   ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ     Terraform (Infrastructure as Code)             ‚îÇ
    ‚îÇ  ‚Ä¢ VPC (10.0.0.0/16, 2 AZs)                       ‚îÇ
    ‚îÇ  ‚Ä¢ EKS Cluster (Kubernetes 1.28)                  ‚îÇ
    ‚îÇ  ‚Ä¢ RDS PostgreSQL 15.7 (db.t3.micro)              ‚îÇ
    ‚îÇ  ‚Ä¢ NAT Gateway ‚Ä¢ Security Groups ‚Ä¢ IAM Roles      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Quick Start

### Prerequisites

```bash
docker --version        # 20.10+
kubectl version        # 1.28+
helm version          # 3.12+
terraform --version   # 1.5+
aws configure         # AWS credentials
```

### Local Development (Minikube)

```bash
# 1. Start Minikube cluster
minikube start --cpus=4 --memory=8192 --driver=docker
minikube addons enable ingress

# 2. Deploy monitoring stack
kubectl create namespace monitoring
kubectl apply -f k8s/prometheus/
kubectl apply -f k8s/grafana/

# 3. Install ArgoCD
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Get ArgoCD password
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d

# 4. Deploy application
helm install my-node-app ./devops-lab-chart \
  --namespace production \
  --create-namespace

# 5. Access application
kubectl port-forward -n production svc/my-node-app 3000:80

# Test endpoints
curl http://localhost:3000/health
curl http://localhost:3000/metrics
```

### AWS Production Deployment

```bash
# 1. Configure AWS and set DB password
aws configure
export TF_VAR_db_password="SecurePassword123!"

# 2. Deploy infrastructure (~15 minutes)
cd terraform/
terraform init
terraform apply -var-file="terraform-free-tier.tfvars"

# 3. Configure kubectl for EKS
aws eks update-kubeconfig --region eu-central-1 --name devops-lab-v2

# 4. Deploy monitoring
kubectl create namespace monitoring
kubectl apply -f k8s/prometheus/
kubectl apply -f k8s/grafana/

# 5. Deploy application with RDS
RDS_HOST=$(cd terraform && terraform output -raw rds_endpoint)
helm install my-node-app ./devops-lab-chart \
  --namespace production \
  --create-namespace \
  --set database.enabled=true \
  --set database.host=$RDS_HOST \
  --set database.password=$TF_VAR_db_password

# 6. Verify deployment
kubectl get all -n production
kubectl get hpa -n production
```

> **üí∞ AWS Cost:** ~‚Ç¨105-110/month (EKS ‚Ç¨75 + NAT ‚Ç¨30). Deploy for 2-3 days (~‚Ç¨7-10) for portfolio, then destroy.

## üìÇ Project Structure

```
devops-lab/
‚îú‚îÄ‚îÄ my-node-app/              # Node.js Express application
‚îÇ   ‚îú‚îÄ‚îÄ server.js             # REST API (/health, /metrics, /db-test)
‚îÇ   ‚îú‚îÄ‚îÄ database.js           # PostgreSQL connection pool
‚îÇ   ‚îú‚îÄ‚îÄ metrics.js            # Prometheus metrics (prom-client)
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile            # Multi-stage Alpine build
‚îÇ   ‚îî‚îÄ‚îÄ package.json          # Dependencies
‚îÇ
‚îú‚îÄ‚îÄ devops-lab-chart/         # Helm chart for Kubernetes
‚îÇ   ‚îú‚îÄ‚îÄ Chart.yaml            # Chart metadata (v1.0.x)
‚îÇ   ‚îú‚îÄ‚îÄ values.yaml           # Configuration (100+ parameters)
‚îÇ   ‚îî‚îÄ‚îÄ templates/            # Kubernetes manifests
‚îÇ       ‚îú‚îÄ‚îÄ deployment.yaml   # 3 replicas, rolling updates
‚îÇ       ‚îú‚îÄ‚îÄ service.yaml      # ClusterIP service
‚îÇ       ‚îú‚îÄ‚îÄ hpa.yaml          # Auto-scaling (2-10 pods)
‚îÇ       ‚îú‚îÄ‚îÄ ingress.yaml      # NGINX Ingress routing
‚îÇ       ‚îú‚îÄ‚îÄ secret.yaml       # Database credentials
‚îÇ       ‚îî‚îÄ‚îÄ configmap.yaml    # Environment variables
‚îÇ
‚îú‚îÄ‚îÄ terraform/                # AWS Infrastructure as Code
‚îÇ   ‚îú‚îÄ‚îÄ main.tf               # Provider configuration
‚îÇ   ‚îú‚îÄ‚îÄ vpc.tf                # VPC, subnets, NAT gateway
‚îÇ   ‚îú‚îÄ‚îÄ eks.tf                # EKS cluster + node groups
‚îÇ   ‚îú‚îÄ‚îÄ rds.tf                # PostgreSQL RDS instance
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf          # Input variables
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf            # Output values
‚îÇ   ‚îî‚îÄ‚îÄ terraform-free-tier.tfvars  # Cost-optimized config
‚îÇ
‚îú‚îÄ‚îÄ k8s/                      # Raw Kubernetes manifests
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/           # Metrics collection
‚îÇ   ‚îú‚îÄ‚îÄ grafana/              # Visualization dashboards
‚îÇ   ‚îú‚îÄ‚îÄ node-app/             # Application manifests
‚îÇ   ‚îú‚îÄ‚îÄ ingress-all.yaml      # Combined ingress rules
‚îÇ   ‚îî‚îÄ‚îÄ argocd-ingress.yaml   # ArgoCD UI access
‚îÇ
‚îú‚îÄ‚îÄ argocd/                   # GitOps configuration
‚îÇ   ‚îú‚îÄ‚îÄ application.yaml      # ArgoCD app definition
‚îÇ   ‚îî‚îÄ‚îÄ project.yaml          # ArgoCD project
‚îÇ
‚îú‚îÄ‚îÄ .github/workflows/        # CI/CD pipelines
‚îÇ   ‚îú‚îÄ‚îÄ build.yaml            # Test on every push
‚îÇ   ‚îú‚îÄ‚îÄ push.yaml             # Build & push Docker image
‚îÇ   ‚îî‚îÄ‚îÄ helm-update.yaml      # Auto-bump chart version
‚îÇ
‚îú‚îÄ‚îÄ Jenkinsfile               # Jenkins pipeline (local dev)
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ load-test.sh          # HPA testing script
    ‚îî‚îÄ‚îÄ nuclear-cleanup.sh    # AWS cleanup utility
```

## üîÑ CI/CD Pipelines

### GitHub Actions (Production)

**Workflow 1: Build & Test** (`.github/workflows/build.yaml`)
- Triggers on every push
- Runs unit tests with npm
- Validates code quality

**Workflow 2: Docker Build & Push** (`.github/workflows/push.yaml`)
- Triggers on push to main
- Builds multi-stage Docker image
- Pushes to `ghcr.io/voynovscloud/devops-lab-nodeapp`

**Workflow 3: Helm Version Bump** (`.github/workflows/helm-update.yaml`)
- Auto-increments chart version
- Commits to Git ‚Üí ArgoCD auto-deploys

### Jenkins (Local Development)

**Pipeline Stages** (`Jenkinsfile`):
1. **Checkout** - Clone repo & get commit SHA
2. **Build** - Create Docker image
3. **Test** - Health check validation
4. **Security Scan** - Trivy vulnerability scan
5. **Deploy to Minikube** - Local K8s deployment

```bash
# Run Jenkins in Docker
docker run -d -p 8080:8080 -p 50000:50000 \
  -v jenkins_home:/var/jenkins_home \
  -v /var/run/docker.sock:/var/run/docker.sock \
  --name jenkins jenkins/jenkins:lts
```

### GitOps with ArgoCD

- **Auto-sync:** Every 3 minutes
- **Self-healing:** Reverts manual changes automatically
- **Source of Truth:** Git repository
- **Prune:** Removes deleted resources

## üìä Monitoring & Observability

### Prometheus (Metrics Collection)
- **Scrape interval:** 30 seconds
- **Retention:** 15 days
- **Storage:** 10Gi persistent volume
- **Auto-discovery:** Kubernetes pods with metrics annotations

### Grafana (Visualization)
- **Access:** Port-forward or Ingress
- **Credentials:** admin / admin (default)
- **Datasource:** Prometheus (pre-configured)
- **Dashboards:** Application monitoring (12 panels)

### Application Metrics
```
# Exposed at /metrics endpoint
http_requests_total                   # Request counter by route
http_request_duration_seconds         # Response time histogram
nodejs_heap_size_used_bytes          # Memory usage
nodejs_eventloop_lag_seconds         # Event loop performance
```

### Access Monitoring

```bash
# Prometheus
kubectl port-forward -n monitoring svc/prometheus 9090:9090

# Grafana
kubectl port-forward -n monitoring svc/grafana 3000:3000
```

## üéØ Key Features

### Auto-Scaling (HPA)
- **Min replicas:** 2
- **Max replicas:** 10
- **CPU target:** 60%
- **Memory target:** 70%
- **Scale up:** CPU/Memory > target for 30s
- **Scale down:** CPU/Memory < target for 5min

Test scaling:
```bash
./scripts/load-test.sh
kubectl get hpa -n production -w
```

### High Availability
- ‚úÖ 3 replicas by default
- ‚úÖ Multi-AZ deployment (AWS)
- ‚úÖ Rolling updates (zero downtime)
- ‚úÖ Health checks (liveness + readiness)
- ‚úÖ Pod anti-affinity (spread across nodes)

### Security
- ‚úÖ Non-root containers (user: appuser)
- ‚úÖ Kubernetes Secrets for credentials
- ‚úÖ RBAC enabled
- ‚úÖ AWS Security Groups
- ‚úÖ Private subnets for database

## üß™ Testing

```bash
# Health check
curl http://localhost:3000/health

# Database connectivity
curl http://localhost:3000/db-test

# Prometheus metrics
curl http://localhost:3000/metrics

# Load test (trigger HPA)
./scripts/load-test.sh

# Watch auto-scaling
kubectl get hpa -n production -w
```

## üßπ Cleanup

### Local (Minikube)
```bash
helm uninstall my-node-app -n production
kubectl delete namespace production monitoring argocd
minikube delete
```

### AWS (IMPORTANT!)
```bash
# Delete application
helm uninstall my-node-app -n production

# Destroy infrastructure
cd terraform/
terraform destroy -var-file="terraform-free-tier.tfvars"

# Verify deletion
aws eks list-clusters --region eu-central-1
aws rds describe-db-instances --region eu-central-1
```

## üéì Skills Demonstrated

| Category | Technologies & Skills |
|----------|----------------------|
| **Containers** | Docker multi-stage builds, Alpine Linux, security best practices |
| **Orchestration** | Kubernetes deployments, services, ConfigMaps, Secrets, Ingress |
| **Package Management** | Helm charts with 100+ configurable parameters |
| **GitOps** | ArgoCD auto-sync, self-healing, declarative deployments |
| **IaC** | Terraform for AWS VPC, EKS, RDS provisioning |
| **CI/CD** | GitHub Actions workflows, Jenkins pipelines, automated testing |
| **Monitoring** | Prometheus metrics, Grafana dashboards, ServiceMonitor |
| **Auto-scaling** | HPA configuration, load testing, performance optimization |
| **Networking** | VPC design, subnet segmentation, NAT gateways, security groups |
| **Security** | RBAC, Secrets management, non-root containers, least privilege |
| **Cloud** | AWS EKS, RDS, EC2, IAM, networking architecture |
| **Databases** | PostgreSQL connection pooling, RDS multi-AZ |

## üìñ Documentation

- **Helm Chart:** [devops-lab-chart/README.md](devops-lab-chart/README.md)
- **Terraform Guide:** [terraform/README.md](terraform/README.md)
- **ArgoCD Setup:** [argocd/README.md](argocd/README.md)
- **Monitoring Alerts:** [docs/ALERTING.md](docs/ALERTING.md)

## üìù License

MIT License - see [LICENSE](LICENSE)

## üë§ Author

**Deyvid Voynov**
- GitHub: [@voynovscloud](https://github.com/voynovscloud)
- Project: [devops-lab](https://github.com/voynovscloud/devops-lab)

---

<div align="center">

**‚≠ê If this project helped you learn DevOps, please star it!**

</div>
